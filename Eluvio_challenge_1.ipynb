{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eluvio_challenge_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-frTQn5nrc8p"
      },
      "source": [
        "**Machine Learning / Data Science Intern - Eluvio** - Coding Challenge - 04/19/2021\n",
        "\n",
        "Option 1 - Data Science/ML\n",
        "\n",
        "Distributed by: Cheng Peng, cpeng2@nd.edu\n",
        "\n",
        "**Problem Description and Backgrounds**\n",
        "1.   Given a table, come up with specific problems and solve properly.\n",
        "2.   Focus on natural language processing.\n",
        "3.   Model can be: a. Predictive modeling. b. Providing analytical insights for some business use cases.\n",
        "4.   Notice: the problem should be treated as a large-scale dataset that will not fit into the RAM of your machine. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaOkRvdg5hGr"
      },
      "source": [
        "**Proposed Problem**\n",
        "\n",
        "Given a news title (text input), we want to build a predictive model to predict its potential popularity such as high popularity, intermediate popularity or low popularity, etc. This task is essentially a text classification problem which is focus on natural language processing.\n",
        "\n",
        "**Technical Details**\n",
        "\n",
        "\n",
        "*   Data:\n",
        "    *   We are using the csv file from Eluvio company: `Eluvio_DS_Challenge.csv`\n",
        "    *   There are 509236 rows of data. Where each row has the following data-point:\n",
        "      *   time_created\n",
        "      *   date_created\n",
        "      *   up_votes\n",
        "      *   down_votes\n",
        "      *   title\n",
        "      *   over_18\n",
        "      *   author\n",
        "      *   category\n",
        "    *   Here, we use up_votes information to define the popularity as the following rules:\n",
        "      * High popularity: [1000,  ),\n",
        "      * Intermediate popularity: [100, 1000),\n",
        "      * Low popularity: [0, 100).\n",
        "    * Class Imbalanced: in our practice, we found the file `Eluvio_DS_Challenge.csv` is an inbalanced dataset. The details to address this issue can be found in the following scripts.\n",
        "    * As we found the values in down_votes column are all 0, hence we do not consider it in this case. Besides, we also found the category is the worldnews type which is highly related to timeliness and freshness like it is rare for customers to search a news posted several years ago and give a thumb up. Since the up_votes is not highly related to the time period, we also do not consider the columns time_created, date_created and category.\n",
        "                \n",
        "\n",
        "*   Hardware Requirements:\n",
        "  *   Python 3.6 and above\n",
        "  *   Pytorch, Pandas, Numpy and Torchtext\n",
        "  *   GPU enabled setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRrn3j8KtAx7"
      },
      "source": [
        "Importing and Pre-Processing the domain data\n",
        "----------------\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "WZlviZA_Ravy",
        "outputId": "ca13bfaf-1110-406c-f022-1a01f751837d"
      },
      "source": [
        "# upload Eluvio_DS_Challenge.csv from your local drive\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-da473e17-08c3-45ea-8203-6218c16d01b1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-da473e17-08c3-45ea-8203-6218c16d01b1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Eluvio_DS_Challenge.csv to Eluvio_DS_Challenge.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXWfSkNOwpIO"
      },
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy\n",
        "#loading dataset, here we only consider the up_votes & title columns to build our predictive model\n",
        "raw_data = pd.read_csv(\"Eluvio_DS_Challenge.csv\", usecols = ['up_votes','title'])\n",
        "raw_data = raw_data.to_numpy()\n",
        "up_votes = raw_data[:, 0]\n",
        "title = raw_data[:, 1]\n",
        "\n",
        "# print('raw_data size shape is:') \n",
        "# print(raw_data.shape)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-j8QDBoAY8C"
      },
      "source": [
        "The first step is to build a vocabulary given the title column. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLEFFgqcAYMZ"
      },
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "counter = Counter()\n",
        "for line in title:\n",
        "    counter.update(tokenizer(line)) # tokenizer(line) convert the line of string into the list of splited word\n",
        "vocab = Vocab(counter, min_freq=1) "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXx9PH51BU9K"
      },
      "source": [
        "The vocabulary block converts a list of tokens into integers as:\n",
        "\n",
        "    [vocab[token] for token in ['dead', 'shoot', 'a']]\n",
        "    >>> [98, 1622, 8]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLjwK3wvB_ef"
      },
      "source": [
        "Prepare the text processing pipeline with the tokenizer and vocabulary. The text and label pipelines will be used to process the values in columns: title and up_votes from the dataset iterators. \n",
        "\n",
        "The text pipeline converts a title string into a list of integers based on the lookup table defined in the vocabulary. The label pipeline converts the up_votes into correspoing level. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTe5dK-B1TaH"
      },
      "source": [
        "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
        "\n",
        "'''\n",
        "\n",
        "Rules for defining popularity levels: [1000, ), high popularity, label 2\n",
        "                                      [100, 1000), intermidiate popularity, lable 1\n",
        "                                      [0, 100), low popularity, label 0\n",
        "'''\n",
        "def label_pipeline(up_votes):\n",
        "  if up_votes >= 1000:\n",
        "    return int(2)\n",
        "  elif up_votes >= 100:\n",
        "    return int(1)\n",
        "  else:\n",
        "    return int(0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdWCT3LeDEua"
      },
      "source": [
        "Generate data batch and iterator \n",
        "--------------------------------\n",
        "In this example, the text entries in the original data batch input are packed into a list and concatenated as a single tensor for the input of ``nn.EmbeddingBag``. The offset is a tensor of delimiters to represent the beginning index of the individual sequence in the text tensor. Label is a tensor saving the labels of indidividual text entries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilnaKUEhDJwy"
      },
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# customize the collate_fn in the DataLoader class\n",
        "def collate_batch(batch):\n",
        "  label_list, text_list, offsets = [], [], [0]\n",
        "  for (_label, _text) in batch:\n",
        "        #  label_list.append(label_pipeline(_label))\n",
        "         label_list.append(_label)\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "  label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "  offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "  text_list = torch.cat(text_list)\n",
        "  return label_list.to(device), text_list.to(device), offsets.to(device)\n",
        "\n",
        "data_iter = []\n",
        "label_list = []\n",
        "for i in range(len(up_votes)):\n",
        "  _label = label_pipeline(up_votes[i])\n",
        "  data_iter.append((_label, title[i]))\n",
        "  label_list.append(_label)\n",
        "# dataloader = DataLoader(data_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg63vqUcQDKK"
      },
      "source": [
        "Define the model\n",
        "----------------\n",
        "\n",
        "The model is composed of the `nn.EmbeddingBag` layer plus a linear layer for the classification purpose. ``nn.EmbeddingBag`` with the default mode of \"mean\" computes the mean value of a “bag” of embeddings. Although the text entries here have different lengths, nn.EmbeddingBag module requires no padding here since the text lengths are saved in offsets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXgbMSlVQLc2"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0BVdXjBTHYp"
      },
      "source": [
        "Initiate an instance\n",
        "--------------------\n",
        "\n",
        "The dataset has 3 labels and therefore the number of classes is 3.\n",
        "\n",
        "   0 : low popularity\n",
        "\n",
        "   1 : medium popularity\n",
        "   \n",
        "   2 : high popularity\n",
        "\n",
        "We build a model with the embedding dimension of 64. The vocab size is equal to the length of the vocabulary instance. The number of classes is equal to the number of labels,\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a9gepQaQkzN"
      },
      "source": [
        "Define functions to train the model and evaluate results.\n",
        "---------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lkLPPPOQinQ"
      },
      "source": [
        "import time\n",
        "\n",
        "def train(model, dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predited_label = model(text, offsets)\n",
        "        loss = criterion(predited_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                              total_acc/total_count))\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predited_label = model(text, offsets)\n",
        "            loss = criterion(predited_label, label)\n",
        "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc/total_count"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3EBB8hZwnTy"
      },
      "source": [
        "Address Imbalanced Dataset.\n",
        "---------------------------------------------------------\n",
        "According to the following histogram figure, we found that up_votes values are mainly distributed from 0 to 100, which is classfied as low popularity class. However, it is difficult to learn the true underlying distribution representing minor classes such as intermidiate popularity and high popularity.\n",
        "\n",
        "Here we choose to use `WeightedRandomSampler` implemente in Pytorch to deal with this imbalanced dataset. \n",
        "\n",
        "We also compare the performance of two models trained with imbalanced dataset and processed imbalanced dataset seperately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "id": "2LJtD3Yq54-M",
        "outputId": "323e4b85-2ef3-4a34-9136-9d10f1191e21"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(up_votes, range=None,bins=100)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([4.73066e+05, 1.09990e+04, 5.52000e+03, 3.33100e+03, 2.21400e+03,\n",
              "        1.69800e+03, 1.37600e+03, 1.16800e+03, 1.00100e+03, 9.03000e+02,\n",
              "        8.11000e+02, 7.75000e+02, 6.91000e+02, 6.30000e+02, 5.61000e+02,\n",
              "        5.06000e+02, 4.49000e+02, 3.73000e+02, 3.47000e+02, 2.95000e+02,\n",
              "        2.48000e+02, 2.33000e+02, 2.28000e+02, 2.06000e+02, 2.25000e+02,\n",
              "        1.99000e+02, 1.73000e+02, 1.74000e+02, 1.60000e+02, 1.39000e+02,\n",
              "        1.22000e+02, 9.60000e+01, 8.30000e+01, 4.80000e+01, 4.10000e+01,\n",
              "        4.00000e+01, 2.30000e+01, 1.70000e+01, 1.60000e+01, 7.00000e+00,\n",
              "        7.00000e+00, 6.00000e+00, 2.00000e+00, 7.00000e+00, 4.00000e+00,\n",
              "        0.00000e+00, 3.00000e+00, 3.00000e+00, 4.00000e+00, 1.00000e+00,\n",
              "        0.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 0.00000e+00,\n",
              "        0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00,\n",
              "        0.00000e+00, 0.00000e+00, 1.00000e+00, 1.00000e+00, 0.00000e+00,\n",
              "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
              "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
              "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
              "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
              "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
              "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
              "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00]),\n",
              " array([0.0, 212.53, 425.06, 637.59, 850.12, 1062.65, 1275.18, 1487.71,\n",
              "        1700.24, 1912.77, 2125.3, 2337.83, 2550.36, 2762.89, 2975.42,\n",
              "        3187.95, 3400.48, 3613.01, 3825.54, 4038.07, 4250.6, 4463.13,\n",
              "        4675.66, 4888.19, 5100.72, 5313.25, 5525.78, 5738.31, 5950.84,\n",
              "        6163.37, 6375.9, 6588.43, 6800.96, 7013.49, 7226.02, 7438.55,\n",
              "        7651.08, 7863.61, 8076.14, 8288.67, 8501.2, 8713.73, 8926.26,\n",
              "        9138.79, 9351.32, 9563.85, 9776.38, 9988.91, 10201.44, 10413.97,\n",
              "        10626.5, 10839.03, 11051.56, 11264.09, 11476.62, 11689.15,\n",
              "        11901.68, 12114.210000000001, 12326.74, 12539.27, 12751.8,\n",
              "        12964.33, 13176.86, 13389.39, 13601.92, 13814.45, 14026.98,\n",
              "        14239.51, 14452.04, 14664.57, 14877.1, 15089.63, 15302.16,\n",
              "        15514.69, 15727.22, 15939.75, 16152.28, 16364.81, 16577.34,\n",
              "        16789.87, 17002.4, 17214.93, 17427.46, 17639.99, 17852.52,\n",
              "        18065.05, 18277.58, 18490.11, 18702.64, 18915.170000000002,\n",
              "        19127.7, 19340.23, 19552.76, 19765.29, 19977.82, 20190.35,\n",
              "        20402.88, 20615.41, 20827.94, 21040.47, 21253.0], dtype=object),\n",
              " <a list of 100 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkyVoTFCkuiY"
      },
      "source": [
        "Build a sampler given the imbalanced training dataset.\n",
        "\n",
        "As the following result shown, we can obtain balanced dataset after using `WeightedRandomSampler`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg4UBh-maaD2",
        "outputId": "4f2ed5d9-d8c2-4b87-9e9b-0ef6a0057d60"
      },
      "source": [
        "from torch.utils.data.sampler import Sampler\n",
        "\n",
        "data = title\n",
        "target = np.array(label_list[:int(len(up_votes)*0.95)])\n",
        "\n",
        "print ('number of labels in the imbalanced training dataset 0/1/2: {}/{}/{}'.format(\n",
        "    len(np.where(target == 0)[0]), len(np.where(target == 1)[0]), len(np.where(target == 2)[0])))\n",
        "\n",
        "class_sample_count = np.array(\n",
        "    [len(np.where(target == t)[0]) for t in np.unique(target)])\n",
        "weight = 1. / class_sample_count\n",
        "weight[0] = weight[0]*0.95\n",
        "samples_weight = np.array([weight[t] for t in target])\n",
        "\n",
        "samples_weight = torch.from_numpy(samples_weight)\n",
        "samples_weigth = samples_weight.double()\n",
        "sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, len(samples_weight))\n",
        "\n",
        "train_loader = DataLoader(data_iter[:int(len(up_votes)*0.95)], batch_size=64, shuffle=False, collate_fn=collate_batch, sampler=sampler)\n",
        "\n",
        "#test whether we get balanced dataset\n",
        "epoch = 0\n",
        "for idx, (label, text, offsets) in enumerate(train_loader):\n",
        "    print (\"number of labels in a batch of balanced training dataset 0/1/2: {}/{}/{}\".format(\n",
        "        len(np.where(label.cpu().numpy() == 0)[0]),\n",
        "        len(np.where(label.cpu().numpy() == 1)[0]),\n",
        "        len(np.where(label.cpu().numpy() == 2)[0]),))\n",
        "    epoch += 1\n",
        "    if epoch == 1:\n",
        "      break"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of labels in the imbalanced training dataset 0/1/2: 436433/33744/13597\n",
            "number of labels in a batch of balanced training dataset 0/1/2: 15/20/29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCBPhvmgRKoY"
      },
      "source": [
        "Split the dataset and run the model\n",
        "-----------------------------------\n",
        "\n",
        "we split the dataset into train/test sets with a split ratio of 0.95 (train) and\n",
        "0.05 (test).\n",
        "\n",
        "Loss function: CrossEntropyLoss\n",
        "\n",
        "Optimizer: stochastic gradient descent method (SGD)\n",
        "\n",
        "Initial learning rate: 5\n",
        "\n",
        "Batch Size: 128\n",
        "\n",
        "Epochs: 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpdjKlbzOEIo"
      },
      "source": [
        "Train with imbalaced dataset directly\n",
        "-----------------------------------\n",
        "We build model1 to train our imbalanced dataset directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WxhHJ9cRNEY",
        "outputId": "be61da70-103b-492d-b11d-eb5159bbbf8a"
      },
      "source": [
        "num_class = 3\n",
        "vocab_size = len(vocab)\n",
        "emsize = 64\n",
        "model1 = TextClassificationModel(vocab_size, emsize, num_class).to(device)\n",
        "# Hyperparameters\n",
        "EPOCHS = 10 # epoch\n",
        "LR = 5  # learning rate\n",
        "BATCH_SIZE = 128 # batch size for training\n",
        "  \n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model1.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "train_dataset = data_iter[:int(len(up_votes)*0.95)]\n",
        "test_dataset = data_iter[int(len(up_votes)*0.95):]\n",
        "\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=False, collate_fn=collate_batch, sampler=sampler)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=False, collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "                             shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(model1, train_dataloader)\n",
        "    accu_test = evaluate(model1, test_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_test:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_test\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'Test accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_test))\n",
        "    print('-' * 59)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| epoch   1 |   500/ 7559 batches | accuracy    0.961\n",
            "| epoch   1 |  1000/ 7559 batches | accuracy    0.947\n",
            "| epoch   1 |  1500/ 7559 batches | accuracy    0.926\n",
            "| epoch   1 |  2000/ 7559 batches | accuracy    0.884\n",
            "| epoch   1 |  2500/ 7559 batches | accuracy    0.890\n",
            "| epoch   1 |  3000/ 7559 batches | accuracy    0.905\n",
            "| epoch   1 |  3500/ 7559 batches | accuracy    0.905\n",
            "| epoch   1 |  4000/ 7559 batches | accuracy    0.910\n",
            "| epoch   1 |  4500/ 7559 batches | accuracy    0.892\n",
            "| epoch   1 |  5000/ 7559 batches | accuracy    0.885\n",
            "| epoch   1 |  5500/ 7559 batches | accuracy    0.891\n",
            "| epoch   1 |  6000/ 7559 batches | accuracy    0.883\n",
            "| epoch   1 |  6500/ 7559 batches | accuracy    0.882\n",
            "| epoch   1 |  7000/ 7559 batches | accuracy    0.890\n",
            "| epoch   1 |  7500/ 7559 batches | accuracy    0.882\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time: 23.91s | Test accuracy    0.880 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 7559 batches | accuracy    0.962\n",
            "| epoch   2 |  1000/ 7559 batches | accuracy    0.947\n",
            "| epoch   2 |  1500/ 7559 batches | accuracy    0.926\n",
            "| epoch   2 |  2000/ 7559 batches | accuracy    0.882\n",
            "| epoch   2 |  2500/ 7559 batches | accuracy    0.890\n",
            "| epoch   2 |  3000/ 7559 batches | accuracy    0.904\n",
            "| epoch   2 |  3500/ 7559 batches | accuracy    0.904\n",
            "| epoch   2 |  4000/ 7559 batches | accuracy    0.910\n",
            "| epoch   2 |  4500/ 7559 batches | accuracy    0.891\n",
            "| epoch   2 |  5000/ 7559 batches | accuracy    0.884\n",
            "| epoch   2 |  5500/ 7559 batches | accuracy    0.891\n",
            "| epoch   2 |  6000/ 7559 batches | accuracy    0.883\n",
            "| epoch   2 |  6500/ 7559 batches | accuracy    0.881\n",
            "| epoch   2 |  7000/ 7559 batches | accuracy    0.890\n",
            "| epoch   2 |  7500/ 7559 batches | accuracy    0.881\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time: 23.60s | Test accuracy    0.880 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 7559 batches | accuracy    0.962\n",
            "| epoch   3 |  1000/ 7559 batches | accuracy    0.947\n",
            "| epoch   3 |  1500/ 7559 batches | accuracy    0.926\n",
            "| epoch   3 |  2000/ 7559 batches | accuracy    0.884\n",
            "| epoch   3 |  2500/ 7559 batches | accuracy    0.890\n",
            "| epoch   3 |  3000/ 7559 batches | accuracy    0.904\n",
            "| epoch   3 |  3500/ 7559 batches | accuracy    0.904\n",
            "| epoch   3 |  4000/ 7559 batches | accuracy    0.910\n",
            "| epoch   3 |  4500/ 7559 batches | accuracy    0.892\n",
            "| epoch   3 |  5000/ 7559 batches | accuracy    0.885\n",
            "| epoch   3 |  5500/ 7559 batches | accuracy    0.891\n",
            "| epoch   3 |  6000/ 7559 batches | accuracy    0.884\n",
            "| epoch   3 |  6500/ 7559 batches | accuracy    0.882\n",
            "| epoch   3 |  7000/ 7559 batches | accuracy    0.890\n",
            "| epoch   3 |  7500/ 7559 batches | accuracy    0.882\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time: 23.74s | Test accuracy    0.880 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 7559 batches | accuracy    0.961\n",
            "| epoch   4 |  1000/ 7559 batches | accuracy    0.947\n",
            "| epoch   4 |  1500/ 7559 batches | accuracy    0.926\n",
            "| epoch   4 |  2000/ 7559 batches | accuracy    0.884\n",
            "| epoch   4 |  2500/ 7559 batches | accuracy    0.890\n",
            "| epoch   4 |  3000/ 7559 batches | accuracy    0.904\n",
            "| epoch   4 |  3500/ 7559 batches | accuracy    0.904\n",
            "| epoch   4 |  4000/ 7559 batches | accuracy    0.910\n",
            "| epoch   4 |  4500/ 7559 batches | accuracy    0.892\n",
            "| epoch   4 |  5000/ 7559 batches | accuracy    0.885\n",
            "| epoch   4 |  5500/ 7559 batches | accuracy    0.891\n",
            "| epoch   4 |  6000/ 7559 batches | accuracy    0.884\n",
            "| epoch   4 |  6500/ 7559 batches | accuracy    0.882\n",
            "| epoch   4 |  7000/ 7559 batches | accuracy    0.890\n",
            "| epoch   4 |  7500/ 7559 batches | accuracy    0.882\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time: 23.71s | Test accuracy    0.880 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 7559 batches | accuracy    0.959\n",
            "| epoch   5 |  1000/ 7559 batches | accuracy    0.945\n",
            "| epoch   5 |  1500/ 7559 batches | accuracy    0.926\n",
            "| epoch   5 |  2000/ 7559 batches | accuracy    0.884\n",
            "| epoch   5 |  2500/ 7559 batches | accuracy    0.890\n",
            "| epoch   5 |  3000/ 7559 batches | accuracy    0.904\n",
            "| epoch   5 |  3500/ 7559 batches | accuracy    0.904\n",
            "| epoch   5 |  4000/ 7559 batches | accuracy    0.909\n",
            "| epoch   5 |  4500/ 7559 batches | accuracy    0.892\n",
            "| epoch   5 |  5000/ 7559 batches | accuracy    0.885\n",
            "| epoch   5 |  5500/ 7559 batches | accuracy    0.891\n",
            "| epoch   5 |  6000/ 7559 batches | accuracy    0.884\n",
            "| epoch   5 |  6500/ 7559 batches | accuracy    0.882\n",
            "| epoch   5 |  7000/ 7559 batches | accuracy    0.890\n",
            "| epoch   5 |  7500/ 7559 batches | accuracy    0.882\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time: 23.42s | Test accuracy    0.880 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 7559 batches | accuracy    0.960\n",
            "| epoch   6 |  1000/ 7559 batches | accuracy    0.945\n",
            "| epoch   6 |  1500/ 7559 batches | accuracy    0.925\n",
            "| epoch   6 |  2000/ 7559 batches | accuracy    0.884\n",
            "| epoch   6 |  2500/ 7559 batches | accuracy    0.890\n",
            "| epoch   6 |  3000/ 7559 batches | accuracy    0.904\n",
            "| epoch   6 |  3500/ 7559 batches | accuracy    0.904\n",
            "| epoch   6 |  4000/ 7559 batches | accuracy    0.909\n",
            "| epoch   6 |  4500/ 7559 batches | accuracy    0.892\n",
            "| epoch   6 |  5000/ 7559 batches | accuracy    0.885\n",
            "| epoch   6 |  5500/ 7559 batches | accuracy    0.891\n",
            "| epoch   6 |  6000/ 7559 batches | accuracy    0.884\n",
            "| epoch   6 |  6500/ 7559 batches | accuracy    0.882\n",
            "| epoch   6 |  7000/ 7559 batches | accuracy    0.890\n",
            "| epoch   6 |  7500/ 7559 batches | accuracy    0.882\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time: 23.84s | Test accuracy    0.880 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 7559 batches | accuracy    0.960\n",
            "| epoch   7 |  1000/ 7559 batches | accuracy    0.945\n",
            "| epoch   7 |  1500/ 7559 batches | accuracy    0.925\n",
            "| epoch   7 |  2000/ 7559 batches | accuracy    0.884\n",
            "| epoch   7 |  2500/ 7559 batches | accuracy    0.890\n",
            "| epoch   7 |  3000/ 7559 batches | accuracy    0.904\n",
            "| epoch   7 |  3500/ 7559 batches | accuracy    0.904\n",
            "| epoch   7 |  4000/ 7559 batches | accuracy    0.909\n",
            "| epoch   7 |  4500/ 7559 batches | accuracy    0.892\n",
            "| epoch   7 |  5000/ 7559 batches | accuracy    0.885\n",
            "| epoch   7 |  5500/ 7559 batches | accuracy    0.891\n",
            "| epoch   7 |  6000/ 7559 batches | accuracy    0.884\n",
            "| epoch   7 |  6500/ 7559 batches | accuracy    0.882\n",
            "| epoch   7 |  7000/ 7559 batches | accuracy    0.890\n",
            "| epoch   7 |  7500/ 7559 batches | accuracy    0.882\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time: 23.49s | Test accuracy    0.880 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 7559 batches | accuracy    0.960\n",
            "| epoch   8 |  1000/ 7559 batches | accuracy    0.945\n",
            "| epoch   8 |  1500/ 7559 batches | accuracy    0.925\n",
            "| epoch   8 |  2000/ 7559 batches | accuracy    0.884\n",
            "| epoch   8 |  2500/ 7559 batches | accuracy    0.890\n",
            "| epoch   8 |  3000/ 7559 batches | accuracy    0.904\n",
            "| epoch   8 |  3500/ 7559 batches | accuracy    0.904\n",
            "| epoch   8 |  4000/ 7559 batches | accuracy    0.909\n",
            "| epoch   8 |  4500/ 7559 batches | accuracy    0.892\n",
            "| epoch   8 |  5000/ 7559 batches | accuracy    0.885\n",
            "| epoch   8 |  5500/ 7559 batches | accuracy    0.891\n",
            "| epoch   8 |  6000/ 7559 batches | accuracy    0.884\n",
            "| epoch   8 |  6500/ 7559 batches | accuracy    0.882\n",
            "| epoch   8 |  7000/ 7559 batches | accuracy    0.890\n",
            "| epoch   8 |  7500/ 7559 batches | accuracy    0.882\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time: 23.37s | Test accuracy    0.880 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 7559 batches | accuracy    0.960\n",
            "| epoch   9 |  1000/ 7559 batches | accuracy    0.945\n",
            "| epoch   9 |  1500/ 7559 batches | accuracy    0.925\n",
            "| epoch   9 |  2000/ 7559 batches | accuracy    0.884\n",
            "| epoch   9 |  2500/ 7559 batches | accuracy    0.890\n",
            "| epoch   9 |  3000/ 7559 batches | accuracy    0.904\n",
            "| epoch   9 |  3500/ 7559 batches | accuracy    0.904\n",
            "| epoch   9 |  4000/ 7559 batches | accuracy    0.909\n",
            "| epoch   9 |  4500/ 7559 batches | accuracy    0.892\n",
            "| epoch   9 |  5000/ 7559 batches | accuracy    0.885\n",
            "| epoch   9 |  5500/ 7559 batches | accuracy    0.891\n",
            "| epoch   9 |  6000/ 7559 batches | accuracy    0.884\n",
            "| epoch   9 |  6500/ 7559 batches | accuracy    0.882\n",
            "| epoch   9 |  7000/ 7559 batches | accuracy    0.890\n",
            "| epoch   9 |  7500/ 7559 batches | accuracy    0.882\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time: 23.41s | Test accuracy    0.880 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   500/ 7559 batches | accuracy    0.960\n",
            "| epoch  10 |  1000/ 7559 batches | accuracy    0.945\n",
            "| epoch  10 |  1500/ 7559 batches | accuracy    0.925\n",
            "| epoch  10 |  2000/ 7559 batches | accuracy    0.884\n",
            "| epoch  10 |  2500/ 7559 batches | accuracy    0.890\n",
            "| epoch  10 |  3000/ 7559 batches | accuracy    0.904\n",
            "| epoch  10 |  3500/ 7559 batches | accuracy    0.904\n",
            "| epoch  10 |  4000/ 7559 batches | accuracy    0.909\n",
            "| epoch  10 |  4500/ 7559 batches | accuracy    0.892\n",
            "| epoch  10 |  5000/ 7559 batches | accuracy    0.885\n",
            "| epoch  10 |  5500/ 7559 batches | accuracy    0.891\n",
            "| epoch  10 |  6000/ 7559 batches | accuracy    0.884\n",
            "| epoch  10 |  6500/ 7559 batches | accuracy    0.882\n",
            "| epoch  10 |  7000/ 7559 batches | accuracy    0.890\n",
            "| epoch  10 |  7500/ 7559 batches | accuracy    0.882\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time: 23.45s | Test accuracy    0.880 \n",
            "-----------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVW3um4gXfmU"
      },
      "source": [
        "Train with imbalaced dataset processed with `WeightedRandomSampler`\n",
        "-----------------------------------\n",
        "We build model2 to train our imbalanced dataset processed with `WeightedRandomSampler`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v5g8QwRXe4A",
        "outputId": "35d19c97-aebc-4235-f802-b77892267f39"
      },
      "source": [
        "model2 = TextClassificationModel(vocab_size, emsize, num_class).to(device)\n",
        "balanced_train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=False, collate_fn=collate_batch, sampler=sampler) # get balanced dataset by using sampler\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model2.parameters(), lr=5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(model2, balanced_train_dataloader)\n",
        "    accu_test = evaluate(model2, test_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_test:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_test\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'Test accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_test))\n",
        "    print('-' * 59)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| epoch   1 |   500/ 7559 batches | accuracy    0.392\n",
            "| epoch   1 |  1000/ 7559 batches | accuracy    0.428\n",
            "| epoch   1 |  1500/ 7559 batches | accuracy    0.444\n",
            "| epoch   1 |  2000/ 7559 batches | accuracy    0.457\n",
            "| epoch   1 |  2500/ 7559 batches | accuracy    0.466\n",
            "| epoch   1 |  3000/ 7559 batches | accuracy    0.477\n",
            "| epoch   1 |  3500/ 7559 batches | accuracy    0.485\n",
            "| epoch   1 |  4000/ 7559 batches | accuracy    0.493\n",
            "| epoch   1 |  4500/ 7559 batches | accuracy    0.501\n",
            "| epoch   1 |  5000/ 7559 batches | accuracy    0.507\n",
            "| epoch   1 |  5500/ 7559 batches | accuracy    0.507\n",
            "| epoch   1 |  6000/ 7559 batches | accuracy    0.516\n",
            "| epoch   1 |  6500/ 7559 batches | accuracy    0.525\n",
            "| epoch   1 |  7000/ 7559 batches | accuracy    0.529\n",
            "| epoch   1 |  7500/ 7559 batches | accuracy    0.528\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time: 24.97s | Test accuracy    0.579 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 7559 batches | accuracy    0.545\n",
            "| epoch   2 |  1000/ 7559 batches | accuracy    0.551\n",
            "| epoch   2 |  1500/ 7559 batches | accuracy    0.555\n",
            "| epoch   2 |  2000/ 7559 batches | accuracy    0.549\n",
            "| epoch   2 |  2500/ 7559 batches | accuracy    0.558\n",
            "| epoch   2 |  3000/ 7559 batches | accuracy    0.552\n",
            "| epoch   2 |  3500/ 7559 batches | accuracy    0.551\n",
            "| epoch   2 |  4000/ 7559 batches | accuracy    0.554\n",
            "| epoch   2 |  4500/ 7559 batches | accuracy    0.555\n",
            "| epoch   2 |  5000/ 7559 batches | accuracy    0.557\n",
            "| epoch   2 |  5500/ 7559 batches | accuracy    0.556\n",
            "| epoch   2 |  6000/ 7559 batches | accuracy    0.560\n",
            "| epoch   2 |  6500/ 7559 batches | accuracy    0.561\n",
            "| epoch   2 |  7000/ 7559 batches | accuracy    0.556\n",
            "| epoch   2 |  7500/ 7559 batches | accuracy    0.565\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time: 25.08s | Test accuracy    0.547 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 7559 batches | accuracy    0.565\n",
            "| epoch   3 |  1000/ 7559 batches | accuracy    0.567\n",
            "| epoch   3 |  1500/ 7559 batches | accuracy    0.564\n",
            "| epoch   3 |  2000/ 7559 batches | accuracy    0.556\n",
            "| epoch   3 |  2500/ 7559 batches | accuracy    0.566\n",
            "| epoch   3 |  3000/ 7559 batches | accuracy    0.567\n",
            "| epoch   3 |  3500/ 7559 batches | accuracy    0.565\n",
            "| epoch   3 |  4000/ 7559 batches | accuracy    0.558\n",
            "| epoch   3 |  4500/ 7559 batches | accuracy    0.565\n",
            "| epoch   3 |  5000/ 7559 batches | accuracy    0.560\n",
            "| epoch   3 |  5500/ 7559 batches | accuracy    0.566\n",
            "| epoch   3 |  6000/ 7559 batches | accuracy    0.567\n",
            "| epoch   3 |  6500/ 7559 batches | accuracy    0.566\n",
            "| epoch   3 |  7000/ 7559 batches | accuracy    0.564\n",
            "| epoch   3 |  7500/ 7559 batches | accuracy    0.566\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time: 25.34s | Test accuracy    0.549 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 7559 batches | accuracy    0.566\n",
            "| epoch   4 |  1000/ 7559 batches | accuracy    0.564\n",
            "| epoch   4 |  1500/ 7559 batches | accuracy    0.563\n",
            "| epoch   4 |  2000/ 7559 batches | accuracy    0.564\n",
            "| epoch   4 |  2500/ 7559 batches | accuracy    0.569\n",
            "| epoch   4 |  3000/ 7559 batches | accuracy    0.562\n",
            "| epoch   4 |  3500/ 7559 batches | accuracy    0.565\n",
            "| epoch   4 |  4000/ 7559 batches | accuracy    0.566\n",
            "| epoch   4 |  4500/ 7559 batches | accuracy    0.565\n",
            "| epoch   4 |  5000/ 7559 batches | accuracy    0.569\n",
            "| epoch   4 |  5500/ 7559 batches | accuracy    0.568\n",
            "| epoch   4 |  6000/ 7559 batches | accuracy    0.574\n",
            "| epoch   4 |  6500/ 7559 batches | accuracy    0.565\n",
            "| epoch   4 |  7000/ 7559 batches | accuracy    0.566\n",
            "| epoch   4 |  7500/ 7559 batches | accuracy    0.566\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time: 25.37s | Test accuracy    0.561 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 7559 batches | accuracy    0.566\n",
            "| epoch   5 |  1000/ 7559 batches | accuracy    0.565\n",
            "| epoch   5 |  1500/ 7559 batches | accuracy    0.568\n",
            "| epoch   5 |  2000/ 7559 batches | accuracy    0.564\n",
            "| epoch   5 |  2500/ 7559 batches | accuracy    0.567\n",
            "| epoch   5 |  3000/ 7559 batches | accuracy    0.566\n",
            "| epoch   5 |  3500/ 7559 batches | accuracy    0.564\n",
            "| epoch   5 |  4000/ 7559 batches | accuracy    0.565\n",
            "| epoch   5 |  4500/ 7559 batches | accuracy    0.566\n",
            "| epoch   5 |  5000/ 7559 batches | accuracy    0.564\n",
            "| epoch   5 |  5500/ 7559 batches | accuracy    0.567\n",
            "| epoch   5 |  6000/ 7559 batches | accuracy    0.567\n",
            "| epoch   5 |  6500/ 7559 batches | accuracy    0.563\n",
            "| epoch   5 |  7000/ 7559 batches | accuracy    0.564\n",
            "| epoch   5 |  7500/ 7559 batches | accuracy    0.563\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time: 25.29s | Test accuracy    0.559 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 7559 batches | accuracy    0.567\n",
            "| epoch   6 |  1000/ 7559 batches | accuracy    0.562\n",
            "| epoch   6 |  1500/ 7559 batches | accuracy    0.561\n",
            "| epoch   6 |  2000/ 7559 batches | accuracy    0.562\n",
            "| epoch   6 |  2500/ 7559 batches | accuracy    0.566\n",
            "| epoch   6 |  3000/ 7559 batches | accuracy    0.564\n",
            "| epoch   6 |  3500/ 7559 batches | accuracy    0.564\n",
            "| epoch   6 |  4000/ 7559 batches | accuracy    0.564\n",
            "| epoch   6 |  4500/ 7559 batches | accuracy    0.563\n",
            "| epoch   6 |  5000/ 7559 batches | accuracy    0.563\n",
            "| epoch   6 |  5500/ 7559 batches | accuracy    0.570\n",
            "| epoch   6 |  6000/ 7559 batches | accuracy    0.563\n",
            "| epoch   6 |  6500/ 7559 batches | accuracy    0.566\n",
            "| epoch   6 |  7000/ 7559 batches | accuracy    0.560\n",
            "| epoch   6 |  7500/ 7559 batches | accuracy    0.569\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time: 25.60s | Test accuracy    0.559 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 7559 batches | accuracy    0.566\n",
            "| epoch   7 |  1000/ 7559 batches | accuracy    0.564\n",
            "| epoch   7 |  1500/ 7559 batches | accuracy    0.566\n",
            "| epoch   7 |  2000/ 7559 batches | accuracy    0.568\n",
            "| epoch   7 |  2500/ 7559 batches | accuracy    0.565\n",
            "| epoch   7 |  3000/ 7559 batches | accuracy    0.563\n",
            "| epoch   7 |  3500/ 7559 batches | accuracy    0.567\n",
            "| epoch   7 |  4000/ 7559 batches | accuracy    0.561\n",
            "| epoch   7 |  4500/ 7559 batches | accuracy    0.564\n",
            "| epoch   7 |  5000/ 7559 batches | accuracy    0.569\n",
            "| epoch   7 |  5500/ 7559 batches | accuracy    0.565\n",
            "| epoch   7 |  6000/ 7559 batches | accuracy    0.563\n",
            "| epoch   7 |  6500/ 7559 batches | accuracy    0.566\n",
            "| epoch   7 |  7000/ 7559 batches | accuracy    0.566\n",
            "| epoch   7 |  7500/ 7559 batches | accuracy    0.567\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time: 25.40s | Test accuracy    0.559 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 7559 batches | accuracy    0.567\n",
            "| epoch   8 |  1000/ 7559 batches | accuracy    0.566\n",
            "| epoch   8 |  1500/ 7559 batches | accuracy    0.568\n",
            "| epoch   8 |  2000/ 7559 batches | accuracy    0.566\n",
            "| epoch   8 |  2500/ 7559 batches | accuracy    0.565\n",
            "| epoch   8 |  3000/ 7559 batches | accuracy    0.569\n",
            "| epoch   8 |  3500/ 7559 batches | accuracy    0.562\n",
            "| epoch   8 |  4000/ 7559 batches | accuracy    0.572\n",
            "| epoch   8 |  4500/ 7559 batches | accuracy    0.561\n",
            "| epoch   8 |  5000/ 7559 batches | accuracy    0.565\n",
            "| epoch   8 |  5500/ 7559 batches | accuracy    0.568\n",
            "| epoch   8 |  6000/ 7559 batches | accuracy    0.565\n",
            "| epoch   8 |  6500/ 7559 batches | accuracy    0.566\n",
            "| epoch   8 |  7000/ 7559 batches | accuracy    0.565\n",
            "| epoch   8 |  7500/ 7559 batches | accuracy    0.566\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time: 25.33s | Test accuracy    0.559 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 7559 batches | accuracy    0.568\n",
            "| epoch   9 |  1000/ 7559 batches | accuracy    0.562\n",
            "| epoch   9 |  1500/ 7559 batches | accuracy    0.566\n",
            "| epoch   9 |  2000/ 7559 batches | accuracy    0.566\n",
            "| epoch   9 |  2500/ 7559 batches | accuracy    0.566\n",
            "| epoch   9 |  3000/ 7559 batches | accuracy    0.564\n",
            "| epoch   9 |  3500/ 7559 batches | accuracy    0.570\n",
            "| epoch   9 |  4000/ 7559 batches | accuracy    0.566\n",
            "| epoch   9 |  4500/ 7559 batches | accuracy    0.563\n",
            "| epoch   9 |  5000/ 7559 batches | accuracy    0.564\n",
            "| epoch   9 |  5500/ 7559 batches | accuracy    0.566\n",
            "| epoch   9 |  6000/ 7559 batches | accuracy    0.566\n",
            "| epoch   9 |  6500/ 7559 batches | accuracy    0.567\n",
            "| epoch   9 |  7000/ 7559 batches | accuracy    0.569\n",
            "| epoch   9 |  7500/ 7559 batches | accuracy    0.571\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time: 25.27s | Test accuracy    0.559 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   500/ 7559 batches | accuracy    0.560\n",
            "| epoch  10 |  1000/ 7559 batches | accuracy    0.561\n",
            "| epoch  10 |  1500/ 7559 batches | accuracy    0.568\n",
            "| epoch  10 |  2000/ 7559 batches | accuracy    0.565\n",
            "| epoch  10 |  2500/ 7559 batches | accuracy    0.564\n",
            "| epoch  10 |  3000/ 7559 batches | accuracy    0.565\n",
            "| epoch  10 |  3500/ 7559 batches | accuracy    0.566\n",
            "| epoch  10 |  4000/ 7559 batches | accuracy    0.568\n",
            "| epoch  10 |  4500/ 7559 batches | accuracy    0.572\n",
            "| epoch  10 |  5000/ 7559 batches | accuracy    0.564\n",
            "| epoch  10 |  5500/ 7559 batches | accuracy    0.566\n",
            "| epoch  10 |  6000/ 7559 batches | accuracy    0.564\n",
            "| epoch  10 |  6500/ 7559 batches | accuracy    0.569\n",
            "| epoch  10 |  7000/ 7559 batches | accuracy    0.565\n",
            "| epoch  10 |  7500/ 7559 batches | accuracy    0.569\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time: 25.38s | Test accuracy    0.559 \n",
            "-----------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VXpDeKuRZIN"
      },
      "source": [
        "Evaluate the model1 and model2 with test dataset\n",
        "------------------------------------\n",
        "Checking the results given the test dataset.\n",
        "\n",
        "In order to test the performance of model1 and model2 on datasets at different popularity levels, we divide test dataset into three different classes which are `high_test_dataset`, `medium_test_dataset` and `low_test_dataset` respectively.\n",
        "\n",
        "As the following results shown, even though the overall test accuracy of model1 is larger that the test accuracy of model2, model1 is unable to identify the minor classes such as intermidiate popularity and high popularity, whereas model2 gives a retively much better performance on these classes compared to model1. In conclusion, using `WeightedRandomSampler` is significant to our predictive model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc-4tex-RR4V",
        "outputId": "cb6127c5-d2f3-4ba6-b277-617e402c5edf"
      },
      "source": [
        "print('Checking the results of different class of test dataset.')\n",
        "high_test_dataset = []\n",
        "medium_test_dataset = []\n",
        "low_test_dataset = []\n",
        "for idx, data in enumerate(test_dataset):\n",
        "  _label, text = data[0], data[1]\n",
        "  if _label == 0:\n",
        "    low_test_dataset.append((_label, text))\n",
        "  elif _label == 1:\n",
        "    medium_test_dataset.append((_label, text))\n",
        "  else:\n",
        "    high_test_dataset.append((_label, text))\n",
        "\n",
        "high_test_dataloader = DataLoader(high_test_dataset, batch_size=BATCH_SIZE,\n",
        "                             shuffle=True, collate_fn=collate_batch)\n",
        "medium_test_dataloader = DataLoader(medium_test_dataset, batch_size=BATCH_SIZE,\n",
        "                             shuffle=True, collate_fn=collate_batch)\n",
        "low_test_dataloader = DataLoader(low_test_dataset, batch_size=BATCH_SIZE,\n",
        "                             shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "high_accu_model1 = evaluate(model1.to(device), high_test_dataloader)\n",
        "medium_accu_model1 = evaluate(model1.to(device), medium_test_dataloader)\n",
        "low_accu_model1 = evaluate(model1.to(device), low_test_dataloader)\n",
        "\n",
        "high_accu_model2 = evaluate(model2.to(device), high_test_dataloader)\n",
        "medium_accu_model2 = evaluate(model2.to(device), medium_test_dataloader)\n",
        "low_accu_model2 = evaluate(model2.to(device), low_test_dataloader)\n",
        "print('Accuracy of model1 and model2 on high popularity test dataset are {:8.3f} and {:8.3f}'.format(high_accu_model1, high_accu_model2))\n",
        "print('Accuracy of model1 and model2 on medium popularity test dataset are {:8.3f} and {:8.3f}'.format(medium_accu_model1, medium_accu_model2))\n",
        "print('Accuracy of model1 and model2 on low test dataset are {:8.3f} and {:8.3f}'.format(low_accu_model1, low_accu_model2))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking the results of different class of test dataset.\n",
            "Accuracy of model1 and model2 on high popularity test dataset are    0.001 and    0.484\n",
            "Accuracy of model1 and model2 on medium popularity test dataset are    0.001 and    0.339\n",
            "Accuracy of model1 and model2 on low test dataset are    1.000 and    0.582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j0yBYenRdyX"
      },
      "source": [
        "Example of news in test dataset\n",
        "---------------------\n",
        "The up_votes of test1 is 3941, which is belongs to high popularity class\n",
        "\n",
        "The up_votes of test2 is 536, which is belongs to intermediate popularity class\n",
        "\n",
        "The up_votes of test3 is 0, which is belongs to low popularity class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFgavR57Re4t",
        "outputId": "db1dd275-fc9a-4dd1-aa0e-0c4397d7da77"
      },
      "source": [
        "ag_news_label = {0: \"low popular\",\n",
        "                 1: \"intermediate popular\",\n",
        "                 2: \"high popular\",\n",
        "                 }\n",
        "\n",
        "def predict(text, text_pipeline, model):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(text_pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() \n",
        "\n",
        "test1 = \"“US to quit TPP trade deal, says Trump - BBC News\"\n",
        "test2 = \"India All Set to Launch a $2 Billion Renewable Energy Equity Fund\"\n",
        "test3 = 'Indian Demonetisation: Most sweeping change in currency policy in the world in decades - Larry Summers'\n",
        "\n",
        "model1 = model1.to(\"cpu\")\n",
        "model2 = model2.to(\"cpu\")\n",
        "\n",
        "print('The test examples of model1:')\n",
        "print(\"Test1 is a %s news\" %ag_news_label[predict(test1, text_pipeline, model1)])\n",
        "print(\"Test2 is a %s news\" %ag_news_label[predict(test2, text_pipeline, model1)])\n",
        "print(\"Test3 is a %s news\" %ag_news_label[predict(test3, text_pipeline, model1)])\n",
        "print()\n",
        "print('The test examples of model2:')\n",
        "print(\"Test1 is a %s news\" %ag_news_label[predict(test1, text_pipeline, model2)])\n",
        "print(\"Test2 is a %s news\" %ag_news_label[predict(test2, text_pipeline, model2)])\n",
        "print(\"Test3 is a %s news\" %ag_news_label[predict(test3, text_pipeline, model2)])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The test examples of model1:\n",
            "Test1 is a low popular news\n",
            "Test2 is a low popular news\n",
            "Test3 is a low popular news\n",
            "\n",
            "The test examples of model2:\n",
            "Test1 is a high popular news\n",
            "Test2 is a intermediate popular news\n",
            "Test3 is a high popular news\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HtHn16UqLn_"
      },
      "source": [
        "Conclusion and Business Insights\n",
        "---------------------\n",
        "In this project, we developed a predictive model to predict the potential popularity given a news' title. It is meaningful to Eluvio company which is the first blockchain-backed 4K streaming and ticketing platform for direct from artist to fan distribution. We can use this model to predict the popularity of each titile and push the most likely popular one to the customers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJLEe5tEakoB"
      },
      "source": [
        "Future Works\n",
        "---------------------\n",
        "\n",
        "\n",
        "1.   Convert this deterministic neural network to Bayesian framework, which is able to give more robust predictions with confidence interval and avoid overfitting problem especially when dataset is in small size or imbalanced.\n",
        "2.   Even though `WeightedRandomSampler` is working when dataset is imbalanced, however it is easy to introduce overfitting or underfitting problems. We can collect dataset at each class equally to build a balanced dataset at beginning.\n",
        "3.   For natural language process, transformer is the most popular model nowadays, I also build a model based on transformer in Eluvio_challenge_2.ipynb. But I did not finish training it due to the computing resource, Eluvio_challenge_2.ipynb is just an extension of this project.\n"
      ]
    }
  ]
}